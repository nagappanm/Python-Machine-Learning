# -*- coding: utf-8 -*-
"""Updated_3_blank_data_Multi-Label Classification with Python and Scikit-Multilearn-.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vNU3poyT1ajYCyOsgBfG6RFpUdueH1EL

### Multilabel Classification with Python

##### Multilabel Dataset Examples
+ https://sci2s.ugr.es/keel/multilabel.php#sub10

![](https://github.com/Jcharis/Python-Machine-Learning/blob/master/Multi_Label_Text_Classification_with_Skmultilearn/multi-class_vs_multi_label_classification_jcharistech.png?raw=1)

#### Solution for Multi-Label Problem
+ Methods for solving Multi-label Classification Problems
    + Problem Transformation
    + Adapted Algorithm
    + Ensemble approaches

#### Problem Transformation
+ It refers to transforming the multi-label problem into single-label problem(s) by using
    - Binary Relevance: treats each label as a separate single class classification
    - Classifier Chains:In this, the first classifier is trained just on the input data and then each next classifier is trained on the input space and all the previous classifiers in the chain.
    - Label Powerset:we transform the problem into a multi-class problem with one multi-class classifier is trained on all unique label combinations found in the training data.

        
#### Adapted Algorithm
+ adapting the algorithm to directly perform multi-label classification, rather than transforming the problem into different subsets of problems.
"""

# Load EDA Pkgs
import pandas as pd
import numpy as np

# Load Data Viz Pkgs
import matplotlib.pyplot as plt
import seaborn as sns

# ML Pkgs
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB,MultinomialNB
from sklearn.metrics import accuracy_score,hamming_loss,classification_report

### Split Dataset into Train and Text
from sklearn.model_selection import train_test_split
# Feature engineering
from sklearn.feature_extraction.text import TfidfVectorizer

#pip install scikit-multilearn
# Multi Label Pkgs
from skmultilearn.problem_transform import BinaryRelevance
from skmultilearn.problem_transform import ClassifierChain
from skmultilearn.problem_transform import LabelPowerset
from skmultilearn.adapt import MLkNN



# Load Dataset
# df = pd.read_csv('https://raw.githubusercontent.com/nagappanm/Python-Machine-Learning/master/Multi_Label_Text_Classification_with_Skmultilearn/data/so_dataset_2_tags.csv')
#df = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/stackoverflow.csv')
# df = pd.read_csv('https://raw.githubusercontent.com/nagappanm/Python-Machine-Learning/master/Multi_Label_Text_Classification_with_Skmultilearn/data/so_dataset_updated.csv')
df = pd.read_csv('https://raw.githubusercontent.com/nagappanm/Python-Machine-Learning/master/Multi_Label_Text_Classification_with_Skmultilearn/data/so_dataset_updated_blank.csv')

df.head()

df.loc[0].title

df.dtypes

# Convert to Float
df['mysql'] = df['mysql'].astype(float)

df.dtypes

# Value Count 
sns.countplot(df['python'])

# Value Count 
sns.countplot(df['php'])

df['php'].value_counts()

df['php'].value_counts().plot(kind='bar')

"""### Text Preprocessing
+ neattext : remove_stopwords
+ pip install neattext
"""
#pip install neattext

import neattext as nt
import neattext.functions as nfx



# Explore For Noise
df['title'].apply(lambda x:nt.TextFrame(x).noise_scan())

# Explore For Noise
df['title'].apply(lambda x:nt.TextExtractor(x).extract_stopwords())

dir(nfx)

# Explore For Noise
df['title'].apply(nfx.remove_stopwords)

corpus = df['title'].apply(nfx.remove_stopwords)

"""### Feature Engineering
+ Build features from our text
+ TFIDF,countvectorizer,bow
"""

tfidf = TfidfVectorizer()

tfidf

# Build Features
Xfeatures = tfidf.fit_transform(corpus).toarray()

Xfeatures

df.head()

# y = df[['mysql', 'python', 'php']]
# y

type(df['Tagsupdated'].iloc[0])

import ast
# df = pd.read_csv('https://raw.githubusercontent.com/nagappanm/Python-Machine-Learning/master/Multi_Label_Text_Classification_with_Skmultilearn/data/so_dataset_updated_blank.csv')
# df['tags'] = df['tags'].apply(lambda x: ast.literal_eval(x))
df['Tagsupdated']=df['Tagsupdated'].fillna("")
df['Tagsupdated'] = df['Tagsupdated'].apply(lambda x: x.split(','))
df.head()
df.tail()

type(df['Tagsupdated'].iloc[0])

from sklearn.preprocessing import MultiLabelBinarizer
multilabel = MultiLabelBinarizer()
y = multilabel.fit_transform(df['Tagsupdated'])
y

multilabel.classes_

# Split Data 
X_train,X_test,y_train,y_test = train_test_split(Xfeatures,y,test_size=0.3,random_state=42)

print(df['title'].shape)
print(X_train.shape)

# Building Our Model
# Estimator + Multilabel Estimator

### Problem Transform
import skmultilearn

dir(skmultilearn)

"""### Binary Relevance classficiation
+ Convert Our Multi-Label Prob to Multi-Class

![](https://github.com/Jcharis/Python-Machine-Learning/blob/master/Multi_Label_Text_Classification_with_Skmultilearn/binary_relevance_multilabel_ml_jcharistech.png?raw=1)
"""

# Convert Our Multi-Label Prob to Multi-Class
# binary classficiation
binary_rel_clf = BinaryRelevance(MultinomialNB())

binary_rel_clf.fit(X_train,y_train)

# Predictions
br_prediction = binary_rel_clf.predict(X_test)

# x = [ 'how to write ml code in python and java i have data but do not know how to do it','java data but do not know how to do it']
x = [ 'how to write code python']
xt = tfidf.transform(x)
multilabel.inverse_transform(binary_rel_clf.predict(xt))

br_prediction
inverseTransformList = multilabel.inverse_transform(br_prediction)
inverseTransformList

# Convert to Array  To See Result
br_prediction.toarray()

# Accuracy
accuracy_score(y_test,br_prediction)

# Hamming Loss :Incorrect Predictions
# The Lower the result the better
hamming_loss(y_test,br_prediction)

"""#### Classifier Chains
+ Preserve Label Correlation

![](https://github.com/Jcharis/Python-Machine-Learning/blob/master/Multi_Label_Text_Classification_with_Skmultilearn/classifier_chains_multilabel_jcharistech.png?raw=1)
"""

def build_model(model,mlb_estimator,xtrain,ytrain,xtest,ytest):
    # Create an Instance
    clf = mlb_estimator(model)
    clf.fit(xtrain,ytrain)
    # Predict
    clf_predictions = clf.predict(xtest)
    # Check For Accuracy
    acc = accuracy_score(ytest,clf_predictions)
    ham = hamming_loss(ytest,clf_predictions)
    result = {"accuracy:":acc,"hamming_score":ham}
    return result

clf_chain_model = build_model(MultinomialNB(),ClassifierChain,X_train,y_train,X_test,y_test)

clf_chain_model

clf = ClassifierChain(MultinomialNB())
clf.fit(X_train,y_train)

# x = [ 'how to write ml code in python and java i have data but do not know how to do it','java data but do not know how to do it']
x = [ 'how to write code python']
xt = tfidf.transform(x)
multilabel.inverse_transform(clf.predict(xt))

"""#### LabelPowerset
![](https://github.com/Jcharis/Python-Machine-Learning/blob/master/Multi_Label_Text_Classification_with_Skmultilearn/labelPowerset_multilabel_ml_jcharistech.png?raw=1)
"""

clf_labelP_model = build_model(MultinomialNB(),LabelPowerset,X_train,y_train,X_test,y_test)

clf_labelP_model

### Apply On A Simple Ttitle/Question

ex1 = df['title'].iloc[0]
ex1

# Vectorized 
vec_example = tfidf.transform([ex1])

# Make our prediction
binary_rel_clf.predict(vec_example).toarray()

multilabel.inverse_transform(binary_rel_clf.predict(vec_example))

clf = LabelPowerset(MultinomialNB())
clf.fit(X_train,y_train)

# x = [ 'how to write ml code in python and java i have data but do not know how to do it','java data but do not know how to do it']
x = [ 'how to write code in python and java']
xt = tfidf.transform(x)
print(multilabel.inverse_transform(clf.predict(xt)));
out = multilabel.inverse_transform(clf.predict(xt));

from collections import OrderedDict
out = list(OrderedDict.fromkeys(out))
print("non duplicated output is: ",out);

import joblib

# Save Model
binary_rel_clf_file = open("binary_rel_clf_model_file.pkl","wb")
joblib.dump(binary_rel_clf,binary_rel_clf_file)
binary_rel_clf_file.close()

# Save Vectorizer
tfidf_vectorizer_file = open("tfidf_vectorizer_SO_tags_file.pkl","wb")
joblib.dump(tfidf,tfidf_vectorizer_file)
tfidf_vectorizer_file.close()

#### Adapted Algorithm
from skmultilearn.adapt import MLkNN


